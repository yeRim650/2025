# 자료구조
### 시간복잡도와 공간복잡도
<details>
<summary>Big-O, Big-Theta, Big-Omega 에 대해 설명해 주세요.</summary>
<div>

- Big-O 표기법은 최악의 경우 시간 복잡도를 나타내며, 알고리짐의 성능을 이해하는데 중요한 도구
- Big-Theta 표기법은 알고리즘의 평균적인 경우의 시간 복잡도
- Big Omega 표기법은 최선의 경우의 시간 복잡도

</div>
</details>
<details>
<summary>다른 것을 사용하지 않고, Big-O를 사용하는 이유가 있을까요?</summary>
<div>

- 알고리즘의 최악의 경우를 생각해야 함

</div>
</details>
<details>
<summary>O(1)은 O(N^2) 보다 무조건적으로 빠른가요?</summary>
<div>

- O(1)는 데이터 크기와 상관없이 일정한 시간이 걸리는 알고리즘
- O(N^2)는 데이터가 많아질 수록 처리시간이 급수적으로 늘어나는 알고리즘
- 데이터가 적다면 일정 수준까지 O(N^2)가 빠르거나 차이 적을 수는 있지만 데이터 양이 많아진다면 차이는 유의미하게 벌어져 O(1)가 훨씬 빠르다는걸 알 수 있다.

</div>
</details>

### 링크드 리스트에 대해 설명해 주세요.
<details>
<summary>일반 배열과, 링크드 리스트를 비교해 주세요.</summary>
<div>

- 배열은 정적자료 구조이며 index로 임의의 접근이 가능하다는 장점이 있어 접근과 탐색이 용이
- 링크드 리스트는 동적 자료구조로 크기를 정할 필요 없으며 노가 존재하여 노드 안에 데이터가 있고, 다음 데이터를 가르키는 주소를 가짐
- 크기의 제한이 없어 데이터 추가, 삭제가 자유롭지만 임의로 접근하는 것이 불가능하여 데이터를 탐색할 때 순차적으로 접근해야함

</div>
</details>

<details>
<summary>링크드 리스트를 사용해서 구현할 수 있는 다른 자료구조에 대해 설명해 주세요.</summary>
<div>

- 링크드 리스트로 구현할 수 있는 자료구조는 대부분 만들 수 있다. 대표적으로 스택이나 큐가 있다.
- 스택 : Last In Fist Out을 하는 자료구조
- 큐 : First In Fist Out을 하는 자료구조

</div>
</details>

### 스택과 큐에 대해서 설명해 주세요.
<details>
<summary>스택 2개로 큐를, 큐 2개로 스택을 만드는 방법과, 그 시간복잡도에 대해 설명해 주세요.</summary>
<div></div>
</details>
<details>
<summary> 시간복잡도를 유지하면서, 배열로 스택과 큐를 구현할 수 있을까요?</summary>
<div></div>
</details>
<details>
<summary>Prefix, Infix, Postfix 에 대해 설명하고, 이를 스택을 활용해서 계산/하는 방법에 대해 설명해 주세요.</summary>
<div>

- Prefix : 연산자를 먼저 표시하고 연산에 필요한 피연산자를 나중에 표기하는 방법이다. (+AB)
- Infix : 연산자를 두 피연산자 사이에 표기하는 방법으로 가장 일반적으로 사용되는 표현 방법이다. (A+B)
- Postfix : 피연산자를 먼저 표시하고 연산자를 나중에 표시하는 방법이다. (AB+)

</div>
</details>
<details>
<summary>Deque는 어떻게 구현할 수 있을까요?</summary>
<div></div>
</details>
<details>
<summary>(C++ 한정) Deque의 Random Access 시간복잡도는 O(1) 입니다. 이게 어떻게 가능한걸까요?</summary>
<div></div>
</details>

### 해시 자료구조에 대해 설명해 주세요.
> 해시란 여러 길이의 데이터를 효율적으로 관리하기 위해 해시 함수를 통해 일정한 길이의 값으로 매핑하는 것을 말한다.
<details>
<summary>값이 주어졌을 때, 어떻게 하면 충돌이 최대한 적은 해시 함수를 설계할 수 있을까요?</summary>
<div>

- Division Method :
값을 버킷 사이즈로 나누어 나머지를 전체 버킷사이즈에서 뺀값으로 사용, 이 때 버킷사이즈는 소수를 사용하고 2의 제곱수와 먼 값을 사용하는 것이 좋다.
- Digit Folding :
값이 문자열일 때 아스키코드로 바꿔 합한 값을 사용, 이때 버킷사이즈를 넘어갈 수 있기 때문에 Divison Method를 함께 사용
- Multiplication Method :
floor(k*A mod 1) * m의 식을 사용한다. A는 0과 1사이의 실수 m은 2의 제곱수를 사용한다.
- Univiersal Hashing :
여러 해시함수를 무작위로 사용한다.
</div>
</details>

<details>
<summary>해시값이 충돌했을 때, 어떤 방식으로 처리할 수 있을까요?</summary>
<div>

- Chaning :
연결리스트를 사용해 중복된 값을 저장한다.
- Open Addressing :
인덱스가 중복되었다면 다른 빈 인덱스를 찾아 저장하는 방법
    - linear probing :
가장 가까운 빈 인덱스를 사용
    - quadratic probing :
2의 제곱수로 탐색하여 빈 인덱스를 사용
    - double hashing probing :
빈 인덱스를 찾을 때 까지 해시 함수를 사용하여 탐색
</div>
</details>

<details>
<summary>Java에서는 해시 충돌을 어떻게 해결했을까?</summary>
<div>

- jdk7까지는 linked list를 사용한 separate chaning을 활용.
- jdk8에서 linked list와 red black tree를 혼용한 separate chaining을 활용.
- 충돌을 한 key-value쌍이 적을때는 linked list로 작동을 한다.
- 충돌을 한 key-value쌍이 특정 임계치에 도달하면 red black tree로 작동을 한다.
</div>
</details>

<details>
<summary>Double Hashing 의 장점과 단점에 대해서 설명하고, 단점을 어떻게 해결할 수 있을지 설명해 주세요.</summary>
<div>

- 장점 : 클러스터링에 영향을 받지 않음
- 단점 : 연산량이 많음, 캐쉬의 효율이 가장 좋지 않음
- primary clustering : 특정 영역에 원소가 몰리는 현상
- secondary clustering : 여러 개의 원소가 동일한 초기 해시 값을 갖는 현상
</div>
</details>

<details>
<summary>다른 자료구조와 비교하여, 해시 테이블은 멀티스레드 환경에서 심각한 수준의 Race Condition 문제에 빠질 위험이 있습니다. 성능 감소를 최소화 한 채로 해당 문제를 해결할 수 있는 방법을 설계해 보세요.</summary>
<div>

- Race Condition(경쟁 상태) 혹은 경쟁 조건이라고도 불리우며 로 둘 이상의 스레드, 프로세스 그외 작업들이 공유 자원(변수, 메모리, 파일 등)에 대해 동시에 접근할 때 누가 언제 데이터를 읽거나 쓰느냐에 따라 결과가 달라질 수 있는 문제것입니다
- 해결방법
    - 상호배제(Mutual exclusion) : 스레드가 공유 변수 또는 공유 스레드를 사용하는 경우 다른 스레드가 동일한 작업을 수행하지 못하도록 배제한다.
    - 프로세스 동기화(Synchronize the process) : 한번에 하나의 프로세스만 공유데이터에 액세스할 수 있도록 한다.
</details>

### 트리와 이진트리, 이진탐색트리에 대해 설명해 주세요.

> 트리 : 데이터를 계층적으로 표현, 사클을 이루지 않고 구성된 데이터 ( 비선형 자료구조, 무방향 비순환 그래프, 계층형 자료구조 )  
> 이진트리 : 자식 노드가 최대 두개인 노드들로 구성된 트리  
> 이진탐색트리 : 모든 왼쪽 자식의 값이 루트나 부모보다 작고, 모든 오른쪽 자식의 값이 루트나 부모보다 큰 값을 가진다.

<details>
<summary>그래프와 트리의 차이가 무엇인가요?</summary>
<div>

- 그래프는 부모-자식 관계가 없지만 트리는 계층형 구조를 가지고 있다
- 들다 노드와 노드간을 연결하는 간선으로 구성된 자료구조
- 트리는 한개의 경로만 가지고 그래프는 두개이상의 경로가 가능
</div>
</details>
<details>
<summary>이진탐색트리에서 중위 탐색을 하게 되면, 그 결과는 어떤 의미를 가지나요?</summary>
<div>

- 중위 순회 : 왼쪽 자식, 노드, 오른쪽 자식 순서로 방문하는 순회 방법
- 트리에 있는 데이터가 정렬된 순서대로 결과가 나옵니다. 
- 오름차순의 형태

</div>
</details>
<details>
<summary>이진탐색트리의 한계점에 대해 설명해주세요.</summary>
<div>

- 편향트리의 경우 링크드 리스트와 같은 형태가 된다.
- 균형 잡힌 트리가 만들어지도록 조건을 설정해야 한다.
</div>
</details>
<details>
<summary>이진탐색트리의 주요 연산에 대한 시간복잡도를 설명하고, 왜 그런 시간복잡도가 도출되는지 설명해 주세요.</summary>
<div>

- 찾고자하는 값과 현재 루트 노드의 값 비교 ->타겟 값이 더 크다면 오른쪽 서브 트리로 ->타겟 값이 더 작다면 왼쪽 서브 트리로
- 포화 트리인 경우 최악의 상황에서는 트리의 높이만큼 탐색하기 때문에 O(logn)
- 편향 트리인 경우 트리의 높이는 n이 되므로, O(n)의 시간 복잡도를 가진다
</div>
</details>
<details>
<summary>이진탐색트리의 값 삽입, 삭제 방법에 대해 설명하고, 어떤식으로 값을 삽입하면 편향이 발생할까요?</summary>
<div>

- 삽입 연산은 새로운 노드를 삽입할 위치를 찾는 과정과 그 위치에 노드를 추가하는 과정으로 구성됨
- 새로운 노드를 삽입할 위치를 찾아야 하기 때문에 탐색과 동일한 시간복잡도를 가짐
- 포화트리 편향트리 O(logn)
- 자식 두 개인 노드를 삭제하는 경우가 최악 시간복잡도
- 삭제할 노드를 찾고 해당 자식 노드도 찾아야 하는 경우이고 최대 시간복잡도는 O(logn)으로 동일
- 오름차순, 내림차순으로 값을 삽입하면 편향이 발생함
</div>
</details>
<details>
<summary>이진탐색트리와 동일한 로직을 사용하면, 삼진탐색트리도 정의할 수 있을까요? 안 된다면, 그 이유에 대해 설명해 주세요.</summary>
<div>

- 동일한 로직을 사용하면 삼진탐색트리를 정의할 수 없음
- 삼진탐색트리는 이진탐색트리와 달리, 3개 구간으로 나눠지므로 중간 자식의 값을 지정하는 방법을 어떻게 하냐에 딸라 달라지기 때문에 정의할 수 없음

</div>
</details>

### 힙에 대해 설명해 주세요.
> 무엇인가를 차곡차곡 쌓아올린 더미  
> 완전 이진 트리의 일종으로 우선순위 큐를 위하여 만들어진 자료구조  
> 부모의 값은 항상 자식(들)의 값보다 크거나(최대 힙[max heap]), 작아야(최소 힙[min heap])하는 규칙
<details>
<summary>힙을 배열로 구현한다고 가정하면, 어떻게 값을 저장할 수 있을까요?</summary>
</details>
<details>
<summary>힙의 삽입, 삭제 방식에 대해 설명하고, 왜 이진탐색트리와 달리 편향이 발생하지 않는지 설명해 주세요.</summary>
</details>
<details>
<summary>힙 정렬의 시간복잡도는 어떻게 되나요? Stable 한가요?</summary>
</details>

### BBST (Balanced Binary Search Tree) 와, 그 종류에 대해 설명해 주세요.
> 균형 이진 탐색 트리는 노드의 삽입과 삭제가 발생할 때 균형을 유지하도록 하는 트리  
> 특정 노드에 대해 최악의 경우에도 탐색, 삽입, 삭제 연산이 O(logn)의 시간 복잡도를 가지도록 설계된 이진 탐색 트리  
> 균형 이진 탐색 트리는 이진 탐색 트리의 한 종류  
> AVL 트리는 각 노드의 왼쪽 서브트리와 오른쪽 서브트리의 높이 차이가 최대 1이 되도록 유지하는 이진 탐색 트리  
> 레드-블랙 트리는 노드가 레드 또는 블랙 색상을 가지며, 몇 가지 색상 속성을 통해 트리의 균형을 유지하는 이진 탐색 트리  
> B-트리는 노드에 여러 키를 저장하며, 모든 리프 노드가 동일한 깊이를 가지도록 유지  
> 2-3-4 트리는 B-트리의 특별한 경우로, 각 노드가 2개, 3개 또는 4개의 자식을 가질 수 잇는 균형 잡힌 트리
<details>
<summary>Red Black Tree는 어떻게 균형을 유지할 수 있을까요?</summary>
<div>

- 리프노드에서 루트노드까지 가는 경로에서 만나는 검은색 노드의 개수가 같다.
</div>
</details>
<details>
<summary>Red Black Tree의 주요 성질 4가지에 대해 설명해 주세요.</summary>
<div>

- 루트 노드는 검은색이다.
- 모든 리프(null lif)는 검은색이다.
- 빨간색 노드의 자식은 검은색이다.
- 모든 리프노드에서 black depth 는 같다.
</div>
</details>
<details>
<summary>2-3-4 Tree, AVL Tree 등의 다른 BBST 가 있음에도, 왜 Red Black Tree가 많이 사용될까요?</summary>
<div>

- 삽입, 삭제 작업 시 균형을 맞추기 위한 작업 횟수가 적다.
- 각 노드당 색깔을 표현하는 데 단 1bit의 저장공간만 필요하다.
- 언제 회전에 의해 균형을 잡아햐 하는지가 쉽게 판별된다.
- 이진 탐색 트리의 함수를 거의 그대로 사용한다.
</div>
</details>

### 정렬 알고리즘에 대해 설명해 주세요.
> 컴퓨터 과학과 수학에서 원소들을 번호순이나 사전 순서 등으로 정렬하는 알고리즘
<details>
<summary>Quick Sort와 Merge Sort를 비교해 주세요.</summary>
<div>

* 퀵 정렬 : 분할 정복 (Devide and Conquer) 기법과 재귀 알고리즘을 이용한 정렬 알고리즘
* 병함 정렬 : 퀵 정렬과 마찬가지로 분할 정복 방법을 통해 정렬이다. 퀵 정렬과 비슷하지만 안정 정렬

* 부분 배열의 구획 : 나뉘어진 배열은 여러 비율로 나뉜다. vs	배열은 항상 반으로 나뉜다.
* 최악의 경우 시간복잡도 : O(n^2) vs O(nlogn)
* 사용 용도 : 작은 크기의 배열에서 잘 동작 vs 어떤 크기의 Dataset에서도 적절히 동작
* 효율성 : 작은 크기 Dataset에서는 병합 정렬보다 빠르다. vs 큰 Dataset에서는 퀵 정렬보다 빠르다.
* 정렬 방식 : 내부 정렬 vs 외부 정렬
* 별도 저장 공간 : 불 필요 vs 필요
* Stable : X(그러나 구현 방식에 따라 가능) vs O
</div>
</details>

<details>
<summary>Quick Sort에서 O(N^2)이 걸리는 예시를 들고, 이를 개선할 수 있는 방법에 대해 설명해 주세요.</summary>
<div>

* 오름차순 혹은 내림차순으로 정렬되어 파티션이 나뉘지 않는 경우
* 중간값과 맨 앞값을 서로 스왑해주면 어느정도 개선이 가능
</div>
</details>

<details>
<summary>Stable Sort가 무엇이고, 어떤 정렬 알고리즘이 Stable 한지 설명해 주세요.</summary>
<div>

* stable sort란 중복된 값이 있을 시 이 순서가 변경되지 않는 정렬을 의미한다. insertion sort, merge sort, bubble sort, counting sort가 있다.
</div>
</details>

<details>
<summary>Merge Sort를 재귀를 사용하지 않고 구현할 수 있을까요?</summary>
<div>

* 큐를 이용하여 구현할 수 있다.
</div>
</details>

<details>
<summary>Bubble, Selection, Insertion Sort의 속도를 비교해 주세요.</summary>
<div>

* 시간복잡도는 모두 O(n^2)
</div>
</details>

### 그래프 자료구조에 대해 설명하고, 이를 구현할 수 있는 두 방법에 대해 설명해 주세요.
> 그래프란 노드와 edge로 구성되어있는 자료구조이다. 이를 구현하기 위해서는 연결 리스트와 배열을 이용하여 구현할 수 있다.
<details>
<summary>각 방법에 대해, "두 정점이 연결되었는지" 확인하는 시간복잡도와 "한 정점에 연결된 모든 정점을 찾는" 시간복잡도, 그리고 공간복잡도를 비교해 주세요.</summary>
<div>

</div>
</details>

<details>
<summary>정점의 개수가 N개, 간선의 개수가 N^3 개라면, 어떤 방식으로 구현하는 것이 효율적일까요?</summary>
<div>

</div>
</details>

<details>
<summary>사이클이 없는 그래프는 모두 트리인가요? 그렇지 않다면, 예시를 들어주세요.</summary>
<div>

</div>
</details>

<details>
<summary>그래프에서 최단거리를 구하는 방법에 대해 설명해 주세요</summary>
<div>

* 그래프에서 최단거리 알고리즘은 다양하게 있음. 다익스트라 알고리즘, 벨만-포드 알고리즘, BFS 등이 있음
* BFS는 가중치가 모두 없거나 모두 동일한 경우, 다익스트라나 밸만포드의 경우는 가중치가 있는 * 그래프에서 최단거리 구할때 용이함. 벨만포드는 특히 음의 가중치를 처리할 때 유용함.
</div>
</details>

### 그래프에서, 최단거리를 구하는 방법에 대해 설명해 주세요.
> 다익스트라 (Dijkstra) 알고리즘(가중치가 있다)  
> 벨만-포드 (Bellman-Ford) 알고리즘(가중치가 있다)  
> 플로이드-워셜 (Floyd-Warshall) 알고리즘(가중치가 있다)  
> BFS(가중치가 없다)  
> 다익스트라(가중치가 없다)  
<details>
<summary>트리에서는 어떤 방식으로 최단거리를 구할 수 있을까요? (위 방법을 사용하지 않고)</summary>
<div>

* LCA 사용
</div>
</details>
<details>
<summary>다익스트라 알고리즘에서, 힙을 사용하지 않고 구현한다면 시간복잡도가 어떻게 변화할까요?</summary>
<div>

|구현 방식 | 시간복잡도 | 비고|  
|힙 사용 안 함 | O(V2+E)O(V^2 + E)O(V2+E) | 노드 수(V)가 작을 때 적합|  
|힙 (우선순위 큐) 사용 | O((V+E)log⁡V)O((V + E) \log V)O((V+E)logV) | 일반적으로 효율적|
</div>
</details>
<details>
<summary>정점의 개수가 N개, 간선의 개수가 N^3 개라면, 어떤 알고리즘이 효율적일까요?</summary>
<div>

단일 출발점 최단 경로만 구하고 싶다면:  
→ 다익스트라 (힙 미사용도 괜찮음)  
→ 어차피 
𝑂
(
𝑁
3
)
O(N 
3
 )이므로 힙의 장점이 크게 부각되지 않음
모든 정점 쌍 최단 경로가 필요하다면:  
→ 플로이드–워셜이 가독성, 구현 난이도 면에서 우수
</div>
</details>
<details>
<summary>A*는 최단 경로 알고리즘으로, 시작 지점에서 목표 지점까지 가장 비용이 적은 경로를 찾습니다.
핵심 아이디어는 현재까지의 거리 + 앞으로의 예상 거리를 합쳐 우선순위를 계산</summary>
<div>

* A* 알고리즘 : A*는 최단 경로 알고리즘으로, 시작 지점에서 목표 지점까지 가장 비용이 적은 경로를 찾습니다.
* 평가 함수
𝑓(𝑛)=𝑔(𝑛)+ℎ(𝑛)
* g(n): 시작점에서 현재 노드 n까지의 실제 비용
* h(n): 목표까지의 예상 비용 (휴리스틱)
→ 이게 A*의 핵심!  

| 항목         | 다익스트라                          | A* 알고리즘                                      |
|--------------|-------------------------------------|--------------------------------------------------|
| 휴리스틱 사용 | ❌ 사용하지 않음                     | ✅ 사용함                                         |
| 우선순위     | 실제 거리 `g(n)`                    | 실제 거리 `g(n)` + 추정 거리 `h(n)`              |
| 성능         | 최단 경로 보장, 느릴 수 있음        | 최단 경로 보장, 빠를 수 있음                     |
| 최적성       | 항상 최적                           | 휴리스틱이 적절하면 최적                         |
| 사용처       | 일반 그래프 탐색                    | 목표가 명확한 탐색 (예: 지도, 게임 AI 등)        |

A* 알고리즘 특징  
✅ 다익스트라보다 빠를 수 있음  
✅ 목표가 있는 탐색에 특화  
✅ 휴리스틱을 잘 짜야 함  
✅ 최적 경로 보장 가능 (단, 휴리스틱이 낙관적일 때)  
</div>
</details>

<details>
<summary>음수 간선이 있을 때와, 음수 사이클이 있을 때 각각 어떤 최단거리 알고리즘을 사용해야 하는지 설명해 주세요.</summary>
<div>

## 상황별 요약

| 상황                      | 가능한 간선 | 특징                                        | 사용 가능한 알고리즘        |
|---------------------------|--------------|---------------------------------------------|------------------------------|
| ✅ 음수 간선만 있음        | 음수 허용     | 최단 경로는 정의 가능                         | **벨만–포드 알고리즘**         |
| ❌ 음수 사이클 있음        | 음수 사이클   | 최단 경로가 무한히 작아짐 (−∞), 정의 불가능     | **최단 경로 정의 불가, 탐지만 가능** |
| ✅ 양수 간선만 있음        | 양수만 허용   | 가장 일반적인 상황                           | **다익스트라, A\*, BFS 등**     |

### 음수 간선이 있을 때 (음수 사이클은 없음)

- 다익스트라는 사용 불가
  - 이미 방문한 노드가 나중에 더 짧은 거리로 갱신될 수 있어 오류 발생
- **벨만–포드 알고리즘**
  - 시간 복잡도: `O(V * E)`
  - 음수 간선을 허용하면서도 **정확한 최단 거리 계산** 가능
  - 동시에 **음수 사이클 탐지** 기능도 포함됨

---

### 음수 사이클이 있을 때

- **최단 경로가 무한히 작아지기 때문에 정의 자체가 불가능**
  - 예: 어떤 노드에서 출발해 음수 사이클을 계속 돌면 비용이 계속 감소
- **벨만–포드로 탐지 가능**
  - 반복 중에도 거리 갱신이 계속 발생하면 음수 사이클 존재

---

### 양수 간선만 있을 때

- 이 경우는 다익스트라, A\*, BFS (가중치 1) 등 다양한 알고리즘 사용 가능
- 일반적으로 가장 빠르고 효율적인 상황

---
</div>
</details>

### 재귀함수에 대해 설명해 주세요.
* 자기 자신을 다시 호출하는 함수를 말해. 문제를 더 작고 같은 형태의 문제로 나눠서 해결하는 방식
<details>
<summary>재귀 함수의 동작 과정을 Call Stack을 활용해서 설명해 주세요.</summary>
<div>

Step	호출 스택	리턴 값  
1	factorial(3)	
2	factorial(3) → factorial(2)	  
3	factorial(3) → factorial(2) → factorial(1)	  
4	factorial(3) → factorial(2)	1  
5	factorial(3)	2  
6	(empty)	6  
</div>
</details>

<details>
<summary>언어의 스펙에 따라, 재귀함수의 최적화를 진행해주는 경우가 있습니다. 어떤 경우에 재귀함수의 최적화가 가능하며, 이를 어떻게 최적화 할 수 있을지 설명해 주세요.</summary>
<div>

- 꼬리 재귀(Tail Recursion) : 스택을 새로 쌓지 않고 덮어씀(재사) → 메모리 절약, Stack Overflow 방지
- 재귀 → 반복 변환 (직접 최적화)
</div>
</details>

### MST가 무엇이고, 어떻게 구할 수 있을지 설명해 주세요
* *MST (Minimum Spanning Tree)**는:
- **무방향 가중치 그래프**에서
- **모든 정점을 연결**하면서
- **총 간선 가중치의 합이 최소**가 되는
- **사이클이 없는 트리 구조**를 말해

즉, 그래프 내의 모든 노드를 최소 비용으로 하나로 연결하는 "가장 저렴한 네트워크"  
#### MST 구하는 알고리즘 2가지

##### 1. Kruskal's Algorithm (크루스칼)

- 간선 중심 (edge-based)
- **가중치 낮은 간선부터 선택**
- **사이클이 생기지 않도록** 선택 (Union-Find 사용)

```
plaintext
복사편집
1. 간선을 가중치 기준으로 정렬
2. 사이클을 만들지 않도록 하나씩 선택 (Union-Find로 판별)
3. 정점 수 - 1 개의 간선을 선택할 때까지 반복

```

> 구현이 간단하고, 간선이 적은 희소 그래프에 유리
> 

---

##### 2. Prim's Algorithm (프림)

- 정점 중심 (vertex-based)
- **임의의 한 정점에서 시작해서**, 연결된 간선 중 최소 가중치를 계속 선택해 나감
- 마치 **BFS + 우선순위 큐** 느낌

```
plaintext
복사편집
1. 아무 정점이나 시작
2. 현재 정점에서 연결된 가장 작은 가중치 간선을 선택
3. 방문 안 한 정점을 트리에 추가
4. 모든 정점이 포함될 때까지 반복

```

> 간선이 많은 밀집 그래프에 유리 (heap 기반으로 구현하면 빠름)

<details>
<summary>Kruskal 알고리즘에서 사용하는 Union-Find 자료구조에 대해 설명해 주세요.</summary>
<div>

Union-Find(또는 Disjoint Set Union, DSU) 자료구조는 서로소 집합(disjoint sets)을 효율적으로 관리하기 위한 자료구조로, Kruskal 알고리즘에서 사이클 발생 여부를 판별할 때 사용됩니다.

📌 핵심 기능
Union-Find는 두 가지 주요 연산을 지원합니다:

Find(x)

원소 x가 속한 집합의 대표(루트) 원소를 반환합니다.

경로 압축(Path Compression)을 통해 성능을 향상시킬 수 있습니다.

Union(x, y)

x와 y가 속한 두 집합을 하나로 합칩니다.

보통 랭크 기반 합치기(Union by Rank) 또는 크기 기반 합치기(Union by Size) 기법을 사용하여 트리 높이를 최소화합니다.

🔧 Kruskal 알고리즘에서의 역할
Kruskal 알고리즘은 간선의 가중치 기준 오름차순 정렬 후, 하나씩 간선을 선택하면서 사이클이 발생하지 않는 경우 해당 간선을 선택합니다.
이때 두 정점이 **같은 집합(같은 트리)**에 속하면 사이클이 생기므로, Find를 통해 루트가 같은지 확인하고,
루트가 다르면 Union으로 병합합니다.

Find, Union 모두 거의 **O(1)**에 가깝게 동작합니다.

정확하게는 아커만 함수의 역함수인 O(α(N)), 거의 상수 시간입니다.
</div>
</details>

<details>
<summary>Kruskal 과 Prim 중, 어떤 것이 더 빠를까요?</summary>
<div>

| 항목 | **Kruskal** | **Prim** |
| --- | --- | --- |
| 접근 방식 | 간선 중심 (Greedy) | 정점 중심 (Greedy) |
| 자료구조 | **Union-Find (Disjoint Set)** | **Priority Queue (Heap)** |
| 정렬 필요 | 간선 가중치 기준 **정렬 필수** | 정렬 불필요, 대신 **최소힙 사용** |
| 시작 조건 | 시작 정점 **상관 없음** | 시작 정점 **필요함** |
| 사이클 처리 | 사이클 생기면 **건너뜀** | 이미 방문한 정점이면 **건너뜀** |
| 그래프 형태 | **희소 그래프**에 유리함 | **조밀 그래프**에 유리함 |
| 시간복잡도 | `O(E log E)` (정렬 + union-find) | `O(E log V)` (heap 연산 중심) |
</div>
</details>

<details>
<summary>Kruskal 과 Prim 알고리즘을 통해 얻어진 결과물은 무조건 트리인가요? 만약 그렇다면 증명해 주세요. 그렇지 않다면, 반례를 설명해 주세요.</summary>
<div>

### 1. **Kruskal 알고리즘 결과는 트리다** — 증명

- 사이클이 생기지 않도록 Union-Find로 체크하며 간선을 추가합니다.
- 모든 정점이 연결될 때까지 간선을 추가하며, 총 `V-1`개의 간선이 선택됩니다.
- 사이클이 없고 정점이 모두 연결됐고 간선이 `V-1`개 → 트리의 정의와 동일합니다.

### ✅ 요약

- 간선 추가 시 사이클 X
- 모든 정점 연결
- 간선 개수 = `V-1`
→ **결과는 트리**

---

### 2. **Prim 알고리즘 결과도 트리다** — 증명

- 시작 정점에서 시작해서, 항상 가장 비용이 적은 간선 하나씩 추가
- 이미 포함된 정점으로 가는 간선은 건너뜀 → 사이클 생기지 않음
- `V`개의 정점을 연결할 때까지 반복하므로, 간선은 `V-1`개

### ✅ 요약

- 방문한 정점 제외하고 확장 → 사이클 X
- 모든 정점 연결
- 간선 개수 = `V-1`
→ **결과는 트리**

</div>
</details>

#### Thread Safe 한 자료구조가 있을까요? 없다면, 어떻게 Thread Safe 하게 구성할 수 있을까요?

<details>
<summary></summary>
<div>

### ✅ 1. Java에서 제공하는 대표적인 Thread-safe 자료구조

### 🔹 `java.util.concurrent` 패키지 기반

- **`ConcurrentHashMap`**
    
    → HashMap의 thread-safe 버전입니다.
    
    → Segment 기반 락 → JDK 8 이후에는 bucket-level 락 또는 CAS 사용.
    
- **`CopyOnWriteArrayList`**, **`CopyOnWriteArraySet`**
    
    → 변경이 거의 없고, 읽기 위주인 경우에 적합.
    
    → 내부적으로 쓰기 시 전체 복사(Copy on Write).
    
- **`BlockingQueue`** 계열
    
    → `ArrayBlockingQueue`, `LinkedBlockingQueue`, `PriorityBlockingQueue` 등
    
    → 생산자-소비자 패턴에 적합.
    

---

### ✅ 2. 동기화 래퍼 사용 (`Collections.synchronizedXXX`)

Java의 `Collections` 유틸 클래스는 기존 자료구조를 동기화된 버전으로 래핑할 수 있습니다.

```java
java
복사편집
List<String> syncList = Collections.synchronizedList(new ArrayList<>());
Map<String, String> syncMap = Collections.synchronizedMap(new HashMap<>());

```

> ✅ 단점: synchronized 블록 사용 → 성능 저하.
> 
> 
> ✅ **iterator 사용 시 별도 `synchronized` 블록 필요**:
> 

```java
java
복사편집
synchronized (syncList) {
    for (String item : syncList) {
        // 작업 수행
    }
}

```

---

### ✅ 3. 직접 Thread-safe하게 구현하려면?

Thread-safe 하지 않은 자료구조(ex. `ArrayList`, `HashMap`)를 멀티스레드 환경에서 안전하게 사용하려면 **동기화**를 직접 처리해야 합니다.

### 방법 1: `synchronized` 키워드 사용

```java
java
복사편집
public class SafeList {
    private final List<String> list = new ArrayList<>();

    public synchronized void add(String item) {
        list.add(item);
    }

    public synchronized String get(int index) {
        return list.get(index);
    }
}

```

### 방법 2: `ReentrantLock` 사용

```java
java
복사편집
public class SafeList {
    private final List<String> list = new ArrayList<>();
    private final ReentrantLock lock = new ReentrantLock();

    public void add(String item) {
        lock.lock();
        try {
            list.add(item);
        } finally {
            lock.unlock();
        }
    }
}

```

---

### ✅ 상황에 따른 선택 기준

| 상황 | 추천 자료구조 |
| --- | --- |
| 읽기 많은 경우 | `CopyOnWriteArrayList`, `ConcurrentHashMap` |
| 쓰기 많은 경우 | `ConcurrentHashMap`, `BlockingQueue` |
| 간단한 동기화만 필요 | `Collections.synchronizedXXX` |
| 세밀한 락 제어 필요 | 직접 구현 (`ReentrantLock`, `AtomicXXX`) |

---

필요하면 `AtomicInteger`, `AtomicReference`, `StampedLock`, `ReadWriteLock` 같은 더 정밀한 도구도 소개해줄 수 있어요.

혹시 어떤 상황에서 thread-safe가 필요한지 예시나 코드가 있다면, 거기에 딱 맞는 자료구조나 구현 방법을 추천해줄 수도 있어요!

## ✅ 1. 정밀한 동시성 도구들

### 🔸 `AtomicInteger`, `AtomicLong`, `AtomicReference`

- **Lock 없이도 원자적 연산이 가능한 클래스**
- 내부적으로는 **CAS (Compare-And-Swap)** 명령어를 사용함
- 매우 빠름 → 락보다 성능 좋음
- `Unsafe` 클래스의 low-level 기능 활용

```java
java
복사편집
AtomicInteger count = new AtomicInteger(0);

// 스레드 간 안전하게 값 증가
count.incrementAndGet();   // ++count
count.addAndGet(5);        // count += 5
count.compareAndSet(10, 20); // 현재 값이 10이면 20으로 변경

```

---

### 🔸 `AtomicReference<T>`

- 객체 참조 자체를 CAS로 원자적으로 교체
- 예: 다중 스레드 환경에서 객체 상태를 안전하게 교체할 때

```java
java
복사편집
AtomicReference<String> ref = new AtomicReference<>("hello");
ref.compareAndSet("hello", "world");

```

---

### 🔸 `ReadWriteLock` (인터페이스) & `ReentrantReadWriteLock` (구현체)

- **읽기/쓰기 락 분리**
    
    → 읽기 동시 허용, 쓰기는 단독 수행
    
    → 읽기 많고 쓰기 적은 경우 매우 효율적
    

```java
java
복사편집
ReentrantReadWriteLock rwLock = new ReentrantReadWriteLock();
Lock readLock = rwLock.readLock();
Lock writeLock = rwLock.writeLock();

readLock.lock();
// 읽기 작업
readLock.unlock();

writeLock.lock();
// 쓰기 작업
writeLock.unlock();

```

---

### 🔸 `StampedLock` (Java 8~)

- `ReadWriteLock` 보다 더 정밀한 락
- **낙관적 락 (Optimistic Read)** 기능 제공 → 성능 향상
- 쓰기 락은 비슷하지만, 낙관적 읽기는 락 없이 값을 먼저 읽고, 유효성 검사 후 문제 있으면 재시도

```java
java
복사편집
StampedLock lock = new StampedLock();
long stamp = lock.tryOptimisticRead();
int value = this.value; // 먼저 읽기
if (!lock.validate(stamp)) {
    // 중간에 다른 스레드가 썼을 경우, 재시도
    stamp = lock.readLock();
    try {
        value = this.value;
    } finally {
        lock.unlockRead(stamp);
    }
}

```

---

## ✅ 2. Java의 대표적인 Thread-safe 자료구조의 내부 구현 방식

### 🔹 `ConcurrentHashMap`

**Java 8 기준:**

- 버킷 단위 락 (fine-grained lock) + CAS
- `put` 시엔 해당 버킷만 락 (synchronized or CAS)
- `get`은 락 없이 volatile 읽기 → 매우 빠름

```java
java
복사편집
ConcurrentHashMap<String, Integer> map = new ConcurrentHashMap<>();
map.put("key", 1);      // 내부적으로 특정 bin에만 CAS 또는 락
map.get("key");         // 락 없이 읽음

```

### 🔹 `CopyOnWriteArrayList`

- 쓰기 시 전체 배열을 복사 → 새로운 배열 생성 후 참조 교체
- 읽기에는 락이 없음
- 변경이 드물고, 읽기가 많을 때 적합

```java
java
복사편집
CopyOnWriteArrayList<String> list = new CopyOnWriteArrayList<>();
list.add("hello");   // 내부적으로 새로운 배열 생성
list.get(0);         // 락 없이 읽기

```

### 🔹 `BlockingQueue` 계열 (`ArrayBlockingQueue`, `LinkedBlockingQueue` 등)

- `put()`과 `take()`에 내부 `ReentrantLock` 사용
- 생산자-소비자 간 스레드 간 데이터 전달에 적합
- `Condition` 객체로 스레드 대기/알림 처리

```java
java
복사편집
BlockingQueue<String> queue = new ArrayBlockingQueue<>(10);

queue.put("item");      // 큐가 꽉 차면 대기
String item = queue.take(); // 비어 있으면 대기

```

---

## ✅ 요약: 언제 뭘 써야 할까?

| 상황 | 추천 도구 |
| --- | --- |
| 숫자 값 증가/감소 | `AtomicInteger`, `LongAdder` |
| 참조 객체 CAS 변경 | `AtomicReference` |
| 읽기 많은 환경 | `ReadWriteLock`, `StampedLock` |
| 성능 중요, 맵 필요 | `ConcurrentHashMap` |
| 읽기 많은 리스트 | `CopyOnWriteArrayList` |
| 생산자-소비자 큐 | `BlockingQueue` 계열 |

</div>
</details>